<!DOCTYPE html><html lang="en-us"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>AWS Auto Scaling, MySQL Read replication - Monospace</title><meta name="description" content="예상하지 못한 트래픽의 폭주와 최적의 성능 및 비용을 고려한 서버 구성, 그리고&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://devnoff.github.io/aws-auto-scaling-mysql-read-replication.html"><link rel="amphtml" href="https://devnoff.github.io/amp/aws-auto-scaling-mysql-read-replication.html"><link type="application/atom+xml" rel="alternate" href="https://devnoff.github.io/feed.xml"><meta property="og:title" content="AWS Auto Scaling, MySQL Read replication"><meta property="og:site_name" content="Monospace"><meta property="og:description" content="예상하지 못한 트래픽의 폭주와 최적의 성능 및 비용을 고려한 서버 구성, 그리고&hellip;"><meta property="og:url" content="https://devnoff.github.io/aws-auto-scaling-mysql-read-replication.html"><meta property="og:type" content="article"><link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin><link href="https://fonts.googleapis.com/css?family=Heebo:400,500%7CPlayfair+Display:400" rel="stylesheet"><link rel="stylesheet" href="https://devnoff.github.io/assets/css/style.css?v=3d2480f7d0fcd5f62ab73511ff97153f"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://devnoff.github.io/aws-auto-scaling-mysql-read-replication.html"},"headline":"AWS Auto Scaling, MySQL Read replication","datePublished":"2016-06-20T11:54","dateModified":"2019-06-13T23:11","description":"예상하지 못한 트래픽의 폭주와 최적의 성능 및 비용을 고려한 서버 구성, 그리고&hellip;","author":{"@type":"Person","name":"devnoff"},"publisher":{"@type":"Organization","name":"devnoff"}}</script><script async src="https://devnoff.github.io/assets/js/lazysizes.min.js?v=9c0e65e25f8f098037678ba0c2be1d9f"></script></head><body><div class="container"><header><a class="logo" href="https://devnoff.github.io/">Monospace</a><div class="top"><div class="top__search"><form action="https://devnoff.github.io/search.html" class="search"><input type="search" name="q" placeholder="search..."></form></div></div></header><main><article class="post u-wrapper"><header class="hero"><p class="post__meta">By <a href="https://devnoff.github.io/authors/devnoff/" rel="author" title="devnoff">devnoff</a> Published on <time datetime="2016-06-20T11:54">June 20, 2016</time></p><h1 class="post__title">AWS Auto Scaling, MySQL Read replication</h1></header><div class="post__entry"><p>예상하지 못한 트래픽의 폭주와 최적의 성능 및 비용을 고려한 서버 구성, 그리고 각 파트의 세팅 과정에 대해 기록하였습니다. 계속 업데이트 되는 문서 입니다.</p><hr><h3>머릿말,</h3><p>웹사이트의 게시글이 소셜네트워크 서비스에서 바이럴이 되면서 예상치 못한 과도한 트래픽이 발생하였다. 우리 서비스에게는 좋은 일 이지만, 이러한 상황에 대비가 되지 않은 인프라 관리자에게는 재앙과 같은 일이다.</p><p>당시 서버 구성은 과도한 트래픽에 대비해서 Route53 을 통해 DNS단에서 두 대의 서버로 강제로 트래픽을 분산 시키는 구성을 가지고 있었다. 나름 서버 한대의 가용 범위를 초과하더라도 감당할 수 있도록 Test 서버의 자원의 일부를 Production deployment 용으로 할당하는 비교적 쉬운 방법으로 대비를 했었는데, 예측을 완전히 벗어나는 엄청난 트래픽이 발생했던 것이다.</p><p>부랴부랴 Production 서버의 snapshot 을 생성하여 EC2 Instance 를 추가하고 Route53 로 트래픽을 강제로 할당하여 상황에 대응하였다. 당시에는 EC2의 Load balancer 및 Auto-scaling 을 사용해 본 적이 없어서 빠르게 적용할 수 있는 위의 방법을 사용하였다.</p><p>Instance 가 추가 되었음에도 Route53 health checks 상태가 100%로 복구 되지는 않았다.  그러나 웹사이트의 접속 자체가 불가능한게 아니라서 추가적인 증설은 진행하지 않고 두었는데, 지금 와서 보면 이는 잘 못 된 판단이다. DNS health check 에서 가용율이 100% 가 아니라는 것은 분명 어딘가에서  트래픽을 잃고 있다는 뜻이기 때문이다.</p><p>트래픽을 잃고 있는 곳은 health check 을 통한  load balancing 이 이루어 지고 있는 부분인데, 30초 마다 health check 을 하여3번 연속 접속실패를 할경우 서버의 이용이 불가능하다고 판단하고 트래픽을 내부에서 설정된 다른 서버로 라우팅 시킨다. 이때 보통 15대의 health checker 가 상태 체크를 하는데 2초에 한번꼴로 체킹이 이루어진다는 뜻이다. 그렇다면 약 2초*3회 / 분산서버대수 만큼의 시간동안 트래픽을 잃게 된다. 서버가 3대라면 2초의 시간동안 트래픽을 잃게되는데 적은 시간 같지만 트래픽이 증가하여 서버가 불안정할 경우 결코 적지 않은 시간 된다. health check  설정을 10초에 단위로 줄일 수도 있는데, 이 경우 1초에 1~2회 정도로 빈번히 체크를 하게 되며 30초단위로(월 0.5불) 체크하는 것에 비해 크지 않은 비용(월 1불)으로 이용할 수 있다.</p><p>아무튼 위의 경험을 통해서 비지니스 상황에 유연하고 신속하게 대응할 수 있는 서버구성을 구축하고자한다.</p><p>웹사이트의 최적화를 통해 서버의 효율을 증대시켜 서버의 가용성을 높일 수가 있기 때문에 인프라적인 대비에 앞에서 선행하고자 검토 했었는데, 이를 통해 얻게 될 서버의 가용성 범위가 물리적 증축에 비해 그리 크지 않고 비지니스의 상황이 더 나은 안정성을 요구함에 따라 인프라적인 대비를 우선 진행 하도록 하였다.</p><h3>현 서버 구성,</h3><ul><li>AWS EC2 Instance(m3.medium $0.098/h) * 2  : Global distribution<ul><li>www01(Production) : WP, RestAPI, MariaDB</li><li>dev01(Development, Production) : WP (Mirror), WP (Dev), MariaDB (Dev)</li></ul></li><li>Aliyun ECS Instance(ecs.n1.tiny, ecs.t1.small) * 2  : China distribution</li><li>AWS Route53<ul><li>Geolocation based routing - GL, CN</li><li>Weighted routing - Load balancing</li></ul></li></ul><h3>변경 후 서버 구성,</h3><p>중국쪽 서비스를 무기한 연기함에 따라 해당지역에 설정된 리소스를 모두 제거한다. 하나의 인스턴스 내에 구동되던 Database 및 웹 서버를 각각 저 사양의 Instance로 나누어 로드 밸런싱이 필요한 상황을 최소화 한다. Auto-scaling, ElastiCache, MySQL read replication 등의 기술을 적용하여 성능 개선 및 가용성, 탄력성 증대를 얻는다.</p><ul><li>AWS EC2 Instance(t2.small $0.04/h) *2<ul><li>static01 : MariaDB (Master), RestAPI, WP</li><li>elastic01 : MariaDB (Read replica), WP</li></ul></li><li>EC2 Elastic load balancer</li><li>AWS ElastiCache (Cache server)</li><li>EC2 Auto scaling</li><li>AWS Route53<ul><li>Weighted routing</li></ul></li></ul><h3>변경 작업,</h3><ol><li>WP에 HyperDB 플러그인 설치하여 Master/Slave 의 Read/Write 설정<ul><li>Master :<ul><li>read hostname - master01</li><li>write hostname - master01</li></ul></li><li>Slave :<ul><li>read hostname - slave01</li><li>write hostname - master01</li></ul></li></ul></li><li>Instance initialize script 작성<ul><li>Pull latest source from repository</li><li>Get database dump and setup slave</li><li>Update hostname alias of hosts file<ul><li>xxx.xxx.xxx.xxx master01</li><li>yyy.yyy.yyy.yyy slave01</li></ul></li></ul></li></ol><h4><strong>1. Instance Setup - static01</strong></h4><p><span style="text-decoration:underline;">Launch new EC2 Instance : Ubuntu 14.04 LTS HVM</span></p><p>EC2 콘솔에서 인스턴스를 추가 한다. t2.micro로 생성하였는데, 추후에 실서버로 돌리때는 t2.small로 업그레이드 할 예정이다.</p><p><span style="text-decoration:underline;">Install EasyEngine</span></p><p>Nginx + PHP(HHVM) + MariaDB + Wordpress 를 간편하게 설치해줌과 동시에 최적의 세팅을 도와주는 <a href="https://easyengine.io/" target="_blank">EasyEngine</a> 을 설치한다.</p><p>[code language="powershell"]<br># install easyengine<br>wget -qO ee rt.cx/ee &amp;&amp; sudo bash ee<br>[/code]</p><p><span style="text-decoration:underline;">Create a site with EasyEngine</span></p><p>EasyEngine을 통해 웹사이트를 설치한다. 대부분의 ee 의 기본 설정값(Wordpress, DB)들은 추후에 별도로 덮어씌어지므로 변경하지 않는다.</p><p>[code language="powershell"]<br># create site on example.com with hhvm<br>ee site create example.com --wp --hhvm<br>[/code]</p><p><span style="text-decoration:underline;">Move MySQL binary log to separate EBS volume</span></p><p>MySQL 로그의 증가로 인해 인스턴스의 용량이 초과되어 서비스가 중단되는 것을 막기 위해 MySQL  바이너리 로그를 별도의 EBS volume에 저장하도록 설정한다. 바이너리 로그 파일은 replication 및 복원용으로만 이용되므로 비용대비 용량이 매우 제한적인 고성능 SSD volume 에 저장해둘 필요가 없다. 대신에 비용이 저렴하여 용량제한에서 매우 자유로운 Cold HDD 를 이용한다.</p><p>참조:<br><a href="http://code.naishe.in/2012/06/mysql-with-replication-and-storage-on.html" target="_blank">Wednesday, June 27, 2012 MySQL with Replication and storage on separate EBS Volume</a><br><a href="http://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/ebs-detaching-volume.html" target="_blank">인스턴스에서 Amazon EBS 볼륨 분리</a></p><p><span style="text-decoration:underline;">Local Memcached vs ElastiCache Memcached vs No cache comparison</span></p><p>Auto-scaling 및 load balancing 을 적용하기 전에 하나의 EC2 인스턴스의 가용성 테스트를 진행하였다. 이 테스트를 통해 확인하고자 하는 것은 인스턴스 하나가 가진 성능을 최대한으로 이용할 수 있는 최적의 세팅을 찾는 것이다.  테스트는 1분 동안 가상의 트래픽을 발생시켜 트래픽량에 따른 응답시간을 측정하는 식으로 진행하였다.</p><p>테스트를 진행한 세팅은 다음과 같다.</p><ul><li>1 EC2 Instance with no cache</li><li>1 EC2 Instance with local cache (Memcached localhost)</li><li>1 EC2 Instance with cloud cache (Memcached on 1 ElastiCache Node)</li></ul><p>테스트를 진행한 페이지는 다음과 같다.</p><ul><li>Landing page</li><li>City page</li><li>Article page</li></ul><p>테스트를 진행한 트래픽 상황은 다음과 같다.</p><ul><li>1 user/sec</li><li>3 users/sec</li><li>5 users/sec</li><li>6 users/sec</li><li>10 ~ 100 users/sec</li></ul><p>결론을 먼저 말하자면, 캐시를 무조건 사용해야 하며 멀티서버 환경에서 캐시의 동기화를 위해 클라우드 캐시를 이용하는 것이 최적의 세팅이다.</p><p>캐시를 사용하지 않은 테스트에서 초당 유저수를 늘릴 수록 그에 비례하여 서버의 응답속도도 늘어났으며 6 users/sec 의 설정으로 트래픽을 발생 시켰을때 데이터베이스 서버가 다운되어 버렸다. 평균 응답 속도는  다음과 같다.</p><ul><li>1 user/sec --- 1000ms</li><li>3 users/sec --- 3500ms</li><li>5 users/sec --- 7000ms</li><li>6 users/sec --- time out</li></ul><p>이에 반해 캐시를 사용했을 때는 초당 2명 이상의 트래픽 환경에서는 캐시를 사용하지 않을때 보다 월등한 성능을 보였다. 최초 응답속도는 트래픽에 따라서 큰 차이 없이 느린편이었다. 이는 캐싱하는데 시간이 걸리기 때문인데, 캐시가 되고난 이후 부터는 아주 빠른 속도를 보였다. 평균 응답속도는 다음과 같다.</p><ul><li>1 user/sec --- 560ms</li><li>5 users/sec --- 510ms</li><li>20 users/sec --- 400ms</li><li>100 users/sec --- 1600ms</li><li>200 users/sec --- 3800ms</li></ul><p>눈에 띠는 점은 초당 200 명의 트래픽을 발생시켜도 서버가 죽지 않는 다는 것이다. 게다가 CloudWatch 상에 5분간의 평균  CPU Utilization 값이 최대 13% 정도로 1분간의 값을 환산 했을때 65% 정도로 안정적인 수치를 보여주었다. 캐시는 로컬호스트에 설치한 Memcached와 ElastiCache의 것을 이용하는 두가지 방법을 이용하였다. 두 세팅모두 비슷한 결과를 보여주었지만, 로컬 인스턴스의 캐시를 이용할 경우 탄력적인 멀티서버환경에서 캐시간 동기화를 세팅하기가 매우 번거롭기 때문에 클라우드 캐시를 사용하기로 결정했다.</p><p>참조:<br><a href="https://easyengine.io/tutorials/php/memcache/" target="_blank">memcache</a><br><a href="http://blog.celingest.com/en/2014/09/26/tutorial-update-elasticache-in-wordpress/" target="_blank">ElastiCache in WordPress</a></p></div><footer class="post__footer"><div class="post__last-updated">This article was updated on June 13, 2019</div><div class="post__footer__col"><ul class="post__tag"><li><a href="https://devnoff.github.io/auto-scaling/">auto-scaling</a></li><li><a href="https://devnoff.github.io/aws/">AWS</a></li><li><a href="https://devnoff.github.io/elasticache/">elasticache</a></li><li><a href="https://devnoff.github.io/mysql/">mysql</a></li><li><a href="https://devnoff.github.io/replication/">replication</a></li></ul><div class="post__share"></div></div><nav class="post__nav"><div class="post__nav__prev">Previous Post<h5><a href="https://devnoff.github.io/aliyun-ubuntu-lemp-hhvm-setup.html" class="inverse" rel="prev">Aliyun Ubuntu LEMP HHVM Setup</a></h5></div><div class="post__nav__next">Next Post<h5><a href="https://devnoff.github.io/spa-auto-deployment-git-jenkins-aws.html" class="inverse" rel="next">SPA 자동 배포 (Git + Jenkins + AWS)</a></h5></div></nav><div class="post__bio"><div><h3><a href="https://devnoff.github.io/authors/devnoff/" class="inverse" title="devnoff">devnoff</a></h3></div></div><div class="post__related"><h3 class="u-h5">Related posts</h3><div class="post__related__wrap"><figure><figcaption><h4><a href="https://devnoff.github.io/spa-auto-deployment-git-jenkins-aws.html" class="inverse">SPA 자동 배포 (Git + Jenkins + AWS)</a></h4><time datetime="2019-06-13T15:00">June 13, 2019</time></figcaption></figure></div></div></footer></article></main><footer class="footer"><div class="footer__copyright">©2019 DEVNOFF</div></footer></div><script defer="defer" src="https://devnoff.github.io/assets/js/jquery-3.2.1.slim.min.js?v=5f48fc77cac90c4778fa24ec9c57f37d"></script><script defer="defer" src="https://devnoff.github.io/assets/js/scripts.min.js?v=16be857f09f55a0c76ea5e92e1f5f9d0"></script></body></html>